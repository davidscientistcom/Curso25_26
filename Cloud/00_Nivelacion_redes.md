## Conceptos Básicos de Redes para Cloud Computing (Unidad de Nivelación)

### Introducción
En esta unidad de nivelación de ~6 horas repasaremos los conceptos fundamentales de redes necesarios para desenvolverse en laboratorios de Cloud Computing con AWS. Está pensada para estudiantes de DAM sin experiencia previa en redes (por ejemplo, provenientes de Turismo u otras ramas). El objetivo es que, al lanzar y conectar instancias en la nube, comprendan la terminología básica y no se pierdan en conceptos de red. No es un curso exhaustivo de redes, sino una guía práctica enfocada a lo imprescindible para trabajar con instancias en AWS. Usaremos explicaciones sencillas, analogías cotidianas y referencias al contexto cloud en todo momento (VPC, subredes, direcciones IP públicas/privadas, grupos de seguridad, etc.). Al final de la unidad deberías saber por qué tu instancia no conecta y cómo solucionarlo .



### ¿Qué es una red?

Una red informática es un conjunto de dispositivos (ordenadores, servidores, móviles, etc.) conectados entre sí para compartir información y recursos. En otras palabras, una red permite que las computadoras se comuniquen: envíen datos de un punto a otro (por ejemplo, navegar por una web significa que tu PC pide datos a otro servidor a través de la red). ¿Para qué sirve una red? Para muchas cosas: compartir archivos e impresoras en una oficina, acceder a Internet desde casa, conectar sucursales de una empresa, o en nuestro caso, para que tu PC pueda gestionar una máquina virtual en AWS. Cuando decimos que algo está “conectado a la red”, significa que ese dispositivo tiene conexión física o inalámbrica a un sistema de comunicaciones que le da acceso al resto de la red (ya sea la red local o Internet). Estar conectado a la red implica que el dispositivo puede intercambiar datos con otros: por ejemplo, una instancia en AWS conectada a la red puede recibir nuestras peticiones SSH o enviar datos a Internet si la configuración lo permite.

LAN, WAN e Internet: Las redes se clasifican según su alcance geográfico. Una LAN (Local Area Network) es una red de área local, limitada a un espacio pequeño (una casa, una oficina, un aula). Con una LAN podemos conectar varios dispositivos cercanos para que compartan recursos rápidamente (por ejemplo, en una oficina una LAN permite que todos accedan a la impresora o a un servidor interno) ￼ ￼. En cambio, una WAN (Wide Area Network) abarca áreas mucho más grandes, conectando múltiples LAN a grandes distancias (por ejemplo, la red de todas las sedes de una empresa a nivel país) ￼. Internet es esencialmente la WAN más grande que existe: la red global que interconecta redes de todo el mundo ￼. Podríamos decir que Internet es “la red de redes”. Para visualizarlo, imagina que tu LAN es tu red doméstica, la WAN es la red de tu proveedor que conecta ciudades, e Internet conecta todas las WAN entre sí. Cuando un dispositivo está conectado a Internet, significa que su red local tiene salida a la red global, ya sea directamente o mediante algún proveedor. Por ejemplo, tu portátil en la LAN de tu casa está conectado a Internet a través del router de tu ISP; una instancia de AWS en una VPC puede estar conectada a Internet si su VPC tiene una Internet Gateway configurada (más adelante detallaremos esto). En resumen: LAN = local, WAN = amplia, Internet = todas las redes conectadas globalmente. Y algo tan sencillo como abrir Google desde una instancia AWS implica que esa instancia pertenece a una red (VPC) que a su vez se conecta hacia Internet.

### Direcciones IP

Para que dos dispositivos en una red se encuentren y se envíen datos, cada uno necesita un identificador único. En las redes informáticas ese identificador es la dirección IP. Podemos pensar en la IP como la dirección postal de tu casa, o el número de teléfono de tu móvil, pero para dispositivos en una red. Así como el cartero necesita tu dirección para entregarte una carta, en Internet los datos se envían a la IP del destinatario ￼ ￼. Una dirección IP es, en su versión más común IPv4, una serie de cuatro números separados por puntos, por ejemplo: 192.168.1.100. Detrás de esos números hay un sistema estándar de direccionamiento (definido por el Protocolo de Internet) que garantiza que cada dirección IP sea única en su red y que los routers puedan dirigir los paquetes correctamente hasta ella ￼ ￼.

Analogía: Podemos usar la analogía del correo postal: en un sobre escribes dirección del destinatario y remitente; con IP ocurre igual, cada paquete de datos lleva la IP de destino (a quién va) y la IP de origen (quién lo envió). Las IP funcionan como direcciones: permiten que los datos lleguen al dispositivo correcto en la red ￼. Por ejemplo, si tu instancia en AWS tiene IP 18.205.4.100 y quieres conectarte por SSH, tu cliente enviará un paquete dirigido a esa IP; los routers de Internet usarán esa dirección para encaminar el paquete a la red de AWS y finalmente a tu instancia. Sin IP correcta, no hay conexión (sería como mandar una carta sin dirección).

IP pública vs. IP privada: No todas las direcciones IP son iguales. Hay IP públicas (ruteables por Internet) y IP privadas (usadas solo dentro de redes locales). Las IP públicas son únicas a nivel mundial y permiten que un dispositivo sea accesible desde cualquier punto de Internet (piensa en la IP pública de un servidor web). En cambio, las IP privadas se utilizan para identificar dispositivos dentro de una red interna y no son válidas en Internet ￼. Por diseño, ciertos rangos de IP están reservados para uso privado (llamados RFC1918). Los más comunes son: 10.0.0.0/8, 172.16.0.0/12 y 192.168.0.0/16, que corresponden a rangos como 10.x.x.x, 172.16–172.31.x.x y 192.168.x.x ￼. Seguro te suenan, porque muchos routers de casa usan 192.168.0.x. Una computadora con IP 192.168.0.5 puede comunicarse dentro de su LAN, pero esa IP no tiene significado fuera (en Internet nadie “ve” esa 192.168… porque los routers descartan ese tráfico privado ￼). Para salir a Internet, los dispositivos privados comparten una IP pública (por ejemplo, la del router mediante NAT, que veremos enseguida).

En AWS, las instancias en una VPC siempre obtienen una IP privada interna (e.g. 172.31.16.8) que las identifica dentro de esa red cloud. Si la instancia está en una subred pública y la configuramos para que tenga IP pública, AWS le asignará además una dirección pública (por ejemplo 3.85.24.117) tomada de su pool global ￼ ￼. La IP privada sirve para que la instancia se comunique con otras dentro de la VPC, mientras que la pública sirve para que tú (desde Internet) puedas alcanzarla. Es importante entender que la IP pública es la “cara” de la instancia hacia Internet, y puede cambiar entre reinicios a menos que uses una fija (en AWS llamadas Elastic IP), mientras que la IP privada es fija mientras la instancia esté viva (persistente durante paradas/arranques) ￼ ￼. Si una instancia no tiene IP pública, solo será accesible desde dentro de su VPC (o mediante VPN u otras soluciones de conectividad privada).

Ejemplos en AWS: Por defecto, al lanzar instancias en la VPC predeterminada de AWS, suelen recibir automáticamente una IP pública ￼. En cambio, en una VPC personalizada, tienes subredes donde decides si asignan IP pública o no. Por ejemplo, puedes tener una instancia web en una subred pública con IP pública, y una base de datos en subred privada solo con IP privada (aislada de Internet). La instancia de BD podrá hablar con la web (porque comparten la VPC) pero nadie desde fuera podrá conectarse a la BD directamente, porque no tiene IP pública y su subred ni siquiera enruta a Internet. Esto es fundamental en arquitectura cloud: diferenciar qué recursos deben ser públicos y cuáles privados. Más adelante, al configurar labs, tendrás que verificar: “¿mi instancia tiene IP pública? ¿puedo usar esa IP para SSH?”. Si no la tiene, a menos que estés en la misma red (p. ej. mediante VPN), no podrás llegar.

### Máscara de subred y subnetting (concepto básico)

Una subred (subnetwork) es, literalmente, una red más pequeña dentro de otra red más grande ￼. ¿Para qué se crean subredes? Principalmente para organizar y aislar el tráfico, mejorar la eficiencia y la seguridad. Imagina una empresa grande: en lugar de una única red gigante para todos los dispositivos, se pueden dividir en subredes (por departamentos, pisos, etc.). Así el tráfico local de una subred no congestiona toda la red y se pueden aplicar políticas distintas. En Internet pasa igual: las subredes permiten que los paquetes viajen por rutas más directas. Siguiendo la analogía postal de Cloudflare: si Alice (en su ciudad) envía una carta a Bob (en la ciudad de al lado), conviene que el correo la lleve directamente a la ciudad de Bob, y no que dé un rodeo innecesario pasando por oficinas en ciudades lejanas ￼. Las subredes acortan caminos: en una red grande, los routers aprenden qué rango (subred) está en qué dirección, y así encaminan los datos eficientemente.

Técnicamente, una subred se define con una máscara de subred, que es un patrón que indica qué parte de la dirección IP corresponde a la red y qué parte a los hosts. Sin entrar en matemáticas, la idea es: si una IP es como “calle y número”, la máscara nos dice hasta dónde llega la “calle” (red) y a partir de dónde es el “número de casa” (host). Por ejemplo, en la subred 192.168.1.0/24, el /24 (255.255.255.0) indica que las primeras 3 cifras (192.168.1) definen la red, y la última cifra identifica hosts. Eso significa que en esa subred caben IP desde 192.168.1.1 hasta 192.168.1.254 (aprox. 254 direcciones útiles). Otra subred podría ser 192.168.2.0/24 para otra área. Dividir en subredes es un poco como tener varias calles dentro del mismo barrio, en lugar de una calle larguísima con miles de casas. Cada subred es un segmento aislado: un dispositivo de la subred A se comunica con uno de la subred B a través de un router (como si saliera de su calle al barrio general y entrara a la otra calle).

En AWS (Cloud), el concepto de subred es crucial. Cuando creas una VPC (Virtual Private Cloud), defines un rango de direcciones IP para esa red (por ejemplo, 10.0.0.0/16 para toda la VPC). Luego, dentro de esa VPC, creas subredes para distribuir tus recursos. Cada subred ocupa una porción del rango mayor. Por ejemplo, puedes dividir 10.0.0.0/16 en subredes /24: 10.0.1.0/24, 10.0.2.0/24, etc. AWS te obliga a asignar cada subred a una Zona de Disponibilidad (AZ) específica (cada subred reside en una única AZ) ￼. En la ilustración, vemos una VPC que abarca dos AZ (columna izquierda A y derecha B). En cada AZ se desplegó una subred pública (verde) y una subred privada (azul). Las subredes públicas tienen una Internet Gateway (IGW, icono morado) que les da salida directa a Internet, mientras que las privadas no ￼. Este esquema típico se utiliza por buenas prácticas: instancias de frontend (servidores web, bastiones) en subredes públicas con acceso externo, e instancias backend (BD, servidores internos) en subredes privadas sin acceso directo externo. Separarlas en subredes diferentes permite aplicar reglas distintas (por ejemplo, las privadas pueden usar un NAT Gateway para iniciar conexiones salientes, pero no reciben tráfico entrante de Internet directamente). En resumen: una subred en cloud es como un segmento aislado donde colocas recursos que comparten requisitos de conectividad. Te ayuda a controlar qué puede salir o entrar de cada segmento. Más adelante, cuando montes labs, verás términos como “VPC” (tu red virtual global en AWS) y “subnets” (subdivisiones de esa red). Tendrás que lanzar instancias en subredes específicas, y saber si esa subred es pública (con IGW) o privada (sin IGW) según si la instancia necesita internet pública o no. Saber esto te ahorrará dolores de cabeza al diagnosticar: “¿Por qué mi instancia no se conecta? Ah, es que está en una subred aislada sin salida a Internet.” 😉

### NAT y salida a Internet

Hablemos ahora de cómo sale una red privada a Internet mediante NAT. NAT significa Network Address Translation o traducción de direcciones de red. Es una función típica de los routers domésticos: en tu casa, tu PC tiene una IP privada (ej. 192.168.0.10) y aun así navegas Internet porque tu router hace NAT. ¿Qué hace exactamente? Simplificando, el router toma las conexiones que tu PC inicia hacia fuera y sustituye la IP origen privada por su propia IP pública. Así, para los servidores externos parece que la conexión viene “desde el router” (IP pública), no desde tu PC privado. Luego el router recuerda esa traducción para devolver la respuesta a tu PC correcto. Esto permite que muchos dispositivos privados compartan una sola IP pública. Además, por diseño, evita accesos directos de fuera a dentro: nadie desde Internet puede iniciar conexión a tu PC 192.168… porque esa dirección no es visible fuera (el router no sabe a qué dispositivo interno enviarla a menos que haya reglas específicas). En resumen, NAT actúa como un portero que traduce y filtra: deja salir a los de dentro (y recuerda quién salió para dejarle entrar la respuesta) pero no deja pasar a desconocidos de fuera hacia adentro, a menos que lo solicites explícitamente.

En AWS ocurre igual cuando queremos que instancias en subredes privadas salgan a Internet. Supongamos que tienes una instancia sin IP pública en una subred sin ruta a IGW (una subred privada). Esa instancia por sí sola “no tiene salida a Internet”, es decir, no puede acceder a servicios externos ni actualizaciones, porque sus paquetes ni siquiera llegan a un gateway público. La solución es colocar un NAT Gateway (puerta de enlace NAT) en una subred pública de la misma VPC, y configurar la ruta de la subred privada para que envíe el tráfico de Internet hacia ese NAT Gateway ￼. El NAT Gateway es un servicio administrado por AWS que hace de traductor: recibe el tráfico de instancias privadas, lo reenvía a Internet usando una IP pública propia, y luego reenvía de vuelta las respuestas. Así, las instancias privadas pueden iniciar conexiones hacia fuera, pero desde fuera nadie puede iniciar una conexión directamente a ellas (porque todo se ve como si viniera del NAT). Esto refuerza la seguridad: los servidores internos pueden descargar parches, conectarse a APIs externas, etc., sin exponerse directamente.

Importante: Una instancia en AWS sin IP pública y sin NAT Gateway configurado no tendrá salida a Internet. Por ejemplo, si lanzas una VM en una subred privada para un servidor de base de datos, de fábrica no podrá ni hacer ping 8.8.8.8 ni apt-get update a menos que la VPC tenga un NAT Gateway al que esté enlazada. Muchas veces en labs la gente se frustra porque “mi instancia no puede descargar tal cosa” y resulta que está en una subred sin NAT. La frase “no tener salida a Internet” significa exactamente eso: que la instancia no puede establecer conexiones con la red global, usualmente por estar aislada tras NAT inexistente o mal configurado. La diferencia con no tener IP pública es sutil: podrías no tener IP pública pero sí tener NAT (caso típico de instancias privadas con NAT Gateway), entonces sí tienes salida a Internet (puedes navegar/descargar) pero no tienes entrada (nadie desde fuera puede dirigirse a tu IP privada directamente). En cambio, sin NAT ni IP pública, estás totalmente aislado.

En resumen, NAT en AWS (mediante NAT Gateway o NAT Instance) permite a instancias privadas hacer tráfico saliente hacia Internet, compartiendo una IP pública del NAT ￼. Si no lo configuras, esas instancias estarán limitadas a la red interna. Por cierto, AWS también tiene el concepto complementario de Internet Gateway (IGW) para subredes públicas: el IGW permite que instancias con IP pública sean accesibles desde Internet (y salgan también). Sin Internet Gateway, ninguna instancia de la VPC es accesible externamente ￼. Por lo tanto, para tener una instancia realmente online, necesitas dos cosas: una Internet Gateway asociada a la VPC y que la instancia esté en una subred cuya tabla de rutas envíe el tráfico internet a esa IGW ￼; y por supuesto, la instancia con IP pública. Si falta cualquiera de esas piezas, la instancia no será alcanzable desde fuera.

Recapitulando: NAT = salen pero no entran; IGW + IP pública = entran y salen (según reglas de firewall). En labs típicos, p.ej. un bastion host (servidor de salto) se coloca en subred pública con IP pública (para que tú puedas entrar por SSH) mientras servidores privados se colocan en subred privada sin IP pública (accesibles solo desde el bastion o via NAT para actualizaciones). Comprender NAT/IGW te permitirá diseñar bien tu red cloud y entender mensajes como “Instance has no internet access”.

### DHCP

DHCP son las siglas de Dynamic Host Configuration Protocol, que traducido es algo así como “protocolo de configuración dinámica de anfitrión” – un nombre rimbombante para un servicio cuyo trabajo principal es asignar automáticamente direcciones IP en una red. En otras palabras, DHCP es el que te da IP sin que tengas que configurar nada a mano. Cuando te conectas a una red WiFi y obtienes IP automáticamente, o cuando una instancia de AWS arranca y ya tiene una IP interna asignada, es gracias al DHCP.

Podemos imaginar el DHCP como un “conserje” de la red: cada vez que un dispositivo nuevo entra, el DHCP le entrega un papelito con su IP, la máscara de subred, la puerta de enlace (gateway) y DNS, etc. (toda la configuración de red básica) ￼. Esto hace la vida más sencilla porque evita tener que poner IP fija manual a cada dispositivo (lo cual en redes grandes sería una locura). Además, DHCP lleva un registro para no asignar la misma IP a dos dispositivos a la vez (evitando conflictos).

¿Por qué las IPs pueden cambiar? Porque con DHCP las direcciones son dinámicas. Normalmente el DHCP “alquila” una IP al dispositivo por un tiempo (llamado tiempo de concesión). Si el dispositivo se desconecta por un rato, puede que al volver reciba otra IP, dependiendo de lo que el servidor DHCP tenga disponible. En casa quizás notas que a veces tu móvil es 192.168.0.5 y otro día 192.168.0.7 – es DHCP reasignando. En redes corporativas, se pueden hacer reservas para que ciertos equipos siempre obtengan la misma IP, pero por defecto es normal que cambien con el tiempo o reinicios.

En AWS, todas las instancias reciben su IP privada via DHCP ￼. Cuando lanzas una instancia en una subred, AWS actúa como servidor DHCP y le asigna una IP privada libre del rango de la subred ￼. Esta IP privada principal permanece asociada mientras la instancia esté viva (aunque puedes detenerla y arrancarla y conservará la misma privada, ya que AWS la reserva para esa instancia). Sin embargo, si terminas la instancia, esa IP vuelve a la “piscina” para otras futuras. Para las IP públicas dinámicas que AWS asigna (no las Elastic), AWS también las gestiona dinámicamente: cada vez que paras/inicias la instancia se libera la pública antigua y se le puede asignar una nueva ￼. Por eso se recomienda usar Elastic IP (IP fija) si necesitas una IP pública permanente. Pero volviendo a DHCP: lo fundamental es entender que las IP asignadas automáticamente no son “propiedad” permanente del recurso, sino configuraciones dinámicas. Si apagamos una instancia y lanzamos otra nueva, no esperemos que mágicamente tenga la misma IP privada o pública a menos que hayamos configurado reservas específicas.

Nota: DHCP no solo asigna la IP, típicamente también comunica la puerta de enlace por defecto (el router de salida) y el/los servidores DNS que debe usar el dispositivo. Así, un equipo recién conectado ya sabe cómo salir de su subred y cómo resolver nombres, sin intervención humana. En AWS, el DHCP interno de la VPC asigna como gateway la IP “.1” de la subred (que suele ser la dirección del router interno de la VPC) y como DNS suele dar la IP del servicio DNS de la VPC (para resolver nombres internos de AWS). Todo eso ocurre tras bambalinas al lanzar instancias.

En resumen, DHCP = configuración automática. ¿Qué implica para ti en labs? Que normalmente no tendrás que configurar la IP manualmente dentro de la instancia; vendrá dada. Pero significa también que puede cambiar si destruyes/creas instancias nuevas, por lo que conviene no fiarse de la IP privada a largo plazo para identificar una máquina (mejor usar nombres o asignar IPs elásticas si necesitas algo estático público). Y si de pronto tu instancia “no tiene IP” (muy raro en AWS porque siempre hay DHCP en VPC), podría indicar un problema de DHCP/routing. En un entorno local, cuando un PC no logra obtener DHCP suele autoconfigurarse en 169.254.x.x (APIPA) ￼, indicando “no encontré servidor DHCP”. En AWS esto no pasa porque el DHCP es parte integral del servicio VPC.

### Puertos y protocolos

Hasta ahora hemos hablado de direcciones IP (quién es quién en la red). Pero cuando dos dispositivos se comunican, normalmente no es solo enviando datos “a la máquina tal”, sino a un servicio específico en esa máquina. Aquí entran los puertos: un puerto es como una extensión interna o puerta lógica dentro de un dispositivo donde “escucha” un cierto servicio ￼. Por ejemplo, un servidor web en la IP 54.85.13.20 podría estar escuchando en el puerto 80. Si envías una petición a 54.85.13.20:80, llegas al servicio web; si envías a 54.85.13.20:22, llegas al servicio SSH (si está corriendo). Los puertos permiten que un mismo servidor con una IP única ofrezca múltiples servicios a la vez sin confundirlos, porque cada servicio usa su puerto dedicado.

Podemos pensar en la IP como la dirección de un edificio, y los puertos como números de apartamento o extensiones. El paquete llega al edificio (IP) y luego se entrega al apartamento correcto (puerto) según a quién va dirigido. Todos los sistemas operativos manejan ~65.535 puertos posibles (0 al 65535) para cada IP. Los puertos bien conocidos (0-1023) están estandarizados para servicios comunes ￼. Algunos esenciales que debes reconocer: puerto 22 = SSH (acceso remoto seguro) ￼, puerto 80 = HTTP (web en texto plano) ￼, puerto 443 = HTTPS (web segura cifrada) ￼. También, por si acaso: puerto 3389 = RDP (escritorio remoto Windows), puerto 3306 = MySQL, puerto 5432 = PostgreSQL, puerto 25 = SMTP (correo), etc. En general, cuando veas un número de puerto sabrás qué tipo de tráfico espera. Por ejemplo, si abres el SG de AWS en el puerto 443, estás permitiendo acceso HTTPS, si abres el 22, es acceso SSH, etc. Si intentas conectar por SSH a una instancia pero en AWS no abriste el puerto 22, es como llegar al edificio pero la puerta del apartamento está cerrada.

Protocolos TCP vs UDP: Los puertos funcionan junto con los protocolos de transporte, principalmente TCP (Transmission Control Protocol) y UDP (User Datagram Protocol). Sin ponernos muy técnicos, la diferencia es cómo se envían los datos:
	•	TCP es como una llamada telefónica: se establece una conexión, hay confirmaciones de recibido, garantía de que los datos llegan completos y en orden. Es fiable pero un poco más lento debido a ese control ￼ ￼. Se usa en aplicaciones donde perder datos no es aceptable, p.ej. navegar webs, transferir archivos, correos, SSH… Prefieres que llegue todo y bien.
	•	UDP es como enviar postales o notas sin acuse de recibo: lanzas los datos “a la red” sin establecer una conexión formal, no hay confirmación ni reintentos. Es más rápido pero no garantiza entrega ￼ ￼. Se usa donde prima la velocidad sobre la confiabilidad, p.ej. en streaming de video/audio, VoIP, juegos online, DNS queries. Si se pierde un paquete da igual, llegan los siguientes.

En resumen, TCP = confiabilidad (retransmite si hay pérdidas, ordena, evita errores); UDP = velocidad (menos sobrecarga) ￼ ￼. Como analogía: TCP es un envío certificado con seguimiento, UDP es tirar un folleto en todos los buzones esperando que llegue. Ejemplos: cuando haces SSH (texto), va por TCP porque cada carácter importa; cuando haces una videollamada, suele ir por UDP, porque es preferible ver en vivo con algún pixel perdido que esperar retrasos por correcciones.

Para nosotros: la mayoría de los labs cloud iniciales involucrarán TCP, porque usarás SSH (TCP/22), HTTP/HTTPS (TCP/80, TCP/443) etc. UDP aparecería si montas algo de DNS o streaming en cloud (menos común para principiantes). Pero está bien saber que si alguna vez pruebas conectarte a un servicio y te dicen “abre UDP 1194” (por ejemplo, para OpenVPN), es otro protocolo y hay que permitirlo específicamente. AWS Security Groups te dejan especificar en cada regla si es TCP, UDP o ICMP, etc., así que debes elegir correctamente según el servicio.

Resumiendo puertos: Piensa en “IP:puerto” como “dirección:departamento”. Y los servicios típicos tienen números fijos (22, 80, 443…) ￼. Un escaneo de puertos en una máquina te dice qué puertas están abiertas (o sea, qué servicios responden). Para nuestras instancias AWS, por defecto ninguna puerta está abierta externamente salvo que lo especifiquemos en el grupo de seguridad (ya llegaremos a firewalls).

### Firewall

Un firewall (cortafuegos) es un componente de seguridad que filtra el tráfico de red según reglas definidas. Actúa como un guardia que decide qué paquetes dejar pasar y cuáles bloquear, típicamente basándose en criterios como la IP de origen/destino, el puerto, el protocolo, etc. Los firewalls pueden ser hardware dedicado o software en cada máquina. En cualquier caso, su función es proteger restringiendo comunicaciones no deseadas o potencialmente peligrosas.

Cuando decimos “bloquear un puerto”, básicamente significa que el firewall está configurado para no permitir tráfico en ese puerto (puede ser en entrada, en salida o ambas). Por ejemplo, si un firewall “bloquea el puerto 22”, ningún intento de conectar por SSH llegará al servicio; el firewall lo descarta antes. Igual con “bloquear puerto 80” en salida, ningún navegador podría acceder a webs (muy usado en entornos corporativos para controlar navegación). Por defecto, muchos firewalls personales bloquean todo puerto entrante no autorizado para evitar intrusiones.

En AWS tenemos los Security Groups (grupos de seguridad), que funcionan como firewalls virtuales por instancia ￼. Cada instancia EC2 está asociada a uno o varios grupos de seguridad, y las reglas de esos grupos determinan qué tráfico entrante está permitido hacia la instancia y qué tráfico saliente puede salir ￼. Por ejemplo, un típico SG para un servidor web permite entrada al puerto 80/443 desde Internet (0.0.0.0/0) y al puerto 22 solo desde la IP del administrador, pero bloquea el resto. Los security groups son stateful, es decir, recuerdan conexiones establecidas: si permites entrada por 443, la respuesta saldrá aunque no tengas regla de salida específica, y viceversa ￼. Un detalle importante: por defecto, al lanzar una instancia, su SG inicial suele no permitir nada de entrada (pero sí permite todo de salida). Esto significa que, si olvidas añadir una regla de SSH entrante, no podrás conectar por más que la instancia tenga IP pública y esté encendida. Siempre verifica el firewall cloud.

Firewall local vs Firewall cloud: En una instancia puedes tener dos niveles de firewall:
	•	El firewall local es el que corre dentro del sistema operativo de la instancia (por ejemplo, iptables/UFW en Linux, o Windows Defender Firewall en Windows). Ese controla el tráfico en el propio host.
	•	El firewall cloud (grupo de seguridad en AWS, o NACL a nivel de subred) controla el tráfico antes de llegar a la instancia, en la capa de la infraestructura de AWS.

¿Cuál es la diferencia práctica? Si el firewall cloud bloquea algo, el tráfico ni siquiera toca tu instancia (AWS lo descarta). Si el SG lo permite pero el firewall del sistema lo bloquea, el tráfico llega a la máquina pero esta lo descarta. Para efectos de labs, muchas veces con ajustar el SG es suficiente porque podrías dejar el firewall interno abierto o deshabilitado. AWS Security Groups son más sencillos de manejar centralmente. Sin embargo, es buena práctica entender ambos. Ejemplo: Podrías tener puerto 80 abierto en el SG, pero dentro de la instancia no tener ningún servicio escuchando o tener el firewall local denegándolo; resultado: no hay respuesta en 80. O viceversa: servicio listo en 80, firewall SO abierto, pero SG cerrado -> tampoco hay acceso. Por eso, al solucionar problemas, revisamos tanto SG (cloud) como firewall OS (local).

Una metáfora: imagina un castillo con muralla exterior (SG) y guardias en la puerta del castillo (firewall del servidor). Si no abres la muralla, nadie llega al castillo; si abres la muralla pero la puerta del castillo está cerrada, tampoco entran. En entornos AWS edu, es común confiar en SG principalmente. De hecho, a menudo en entornos cloud se deshabilita el firewall interno o se configura para que no interfiera, y se maneja todo con SG y Network ACLs. Security Group vs NACL: Por cierto, además de SG por instancia, AWS tiene Network ACLs a nivel de subred, que son firewalls stateless que aplican a todo tráfico de la subred. Suelen dejarse en “allow all” en labs simples, pero en producción añaden otra capa (p.ej. bloquear puertos a nivel subnet).

Resumiendo: un firewall controla qué tráfico pasa o no pasa. En AWS, el Grupo de Seguridad es “la muralla” de cada instancia: define qué IPs/puertos entrantes están permitidos. Un SG por defecto en blanco bloquea todo (excepto respuestas a salidas) ￼. Para acceder a tu instancia debes abrir el puerto 22 al menos para tu IP, etc. Si luego montas un servidor web en el puerto 8080, tendrás que agregar una regla permitiendo 8080, si no te parecerá “no funciona” aunque el servidor esté corriendo. La diferencia entre firewall local y cloud radica en dónde se aplica, pero la funcionalidad base es la misma. Como administradores cloud juniors, nunca olviden revisar el SG cuando no puedan conectar 😅.

### DNS (Domain Name System) – nivel básico

Las DNS son a menudo llamadas “la agenda de contactos de Internet”. ¿Por qué? Porque trabajar solo con direcciones IP sería engorroso para los humanos. En lugar de recordar que la IP de Google es 142.250.190.78, simplemente tecleamos google.com. DNS es el sistema que se encarga de traducir esos nombres de dominio a sus direcciones IP correspondientes ￼ ￼. Igual que en el móvil buscas por nombre “Mamá” y el teléfono marca el número guardado, en Internet tu PC pregunta al DNS “¿qué IP tiene google.com?” y DNS responde “142.250.190.78” (por ejemplo), entonces tu PC ya se conecta allí. Sin DNS tendrías que memorizar cientos de números.

Cómo funciona (brevemente): Cuando escribes un nombre de host (por ejemplo midb.corp.local o www.amazon.com), tu dispositivo contacta a un servidor DNS (normalmente el de tu proveedor o el que configure DHCP, ej. 8.8.8.8 de Google) y le consulta por ese nombre. El sistema DNS es jerárquico; si el primer servidor no lo sabe, va preguntando a otros (primero a los root, luego al DNS autoritativo del dominio, etc.) ￼ ￼. Finalmente obtiene la IP y te la da. Todo esto suele ocurrir en milisegundos y queda transparente para el usuario.

Analogía agenda telefónica: Siguiendo la analogía, podríamos decir: el nombre de dominio es el nombre de la persona, la IP es el número de teléfono. Un servidor DNS es como la operadora o la propia guía: tú dices “busco PizzaPepinillos.com” y DNS te devuelve “ah, llame al 52.85.133.95”. De hecho, se suele describir DNS directamente como “la guía telefónica de Internet” ￼. En ambientes corporativos internos también hay DNS para resolver nombres locales (por ejemplo archivo.empresa a la IP interna X).

¿Por qué necesitas DNS incluso en cloud? Porque aunque estés trabajando con instancias y servicios en AWS, seguirás usando nombres para muchas cosas. AWS asigna nombres DNS internos a las instancias (ej: ip-10-0-1-25.ec2.internal) que resuelven a sus IP privadas, y también puede asignar nombres públicos (ec2-3-85-10-2.compute-1.amazonaws.com) que apuntan a la IP pública. Cuando haces SSH probablemente usarás la IP directamente, pero podrías usar el nombre público. Además, servicios como AWS Lambda, S3, RDS y muchísimos otros se acceden vía nombres DNS (por ejemplo mybucket.s3.amazonaws.com o el endpoint de una base de datos RDS es un nombre DNS). Si tu instancia no pudiera resolver DNS, tendría problemas para alcanzar otros servicios por nombre. Por eso, en cada VPC AWS hay un resolver DNS interno que suele estar disponible en la IP .2 de la rango VPC para que las instancias puedan resolver nombres (tanto de Amazon como externos, si tienen salida a Internet).

Otro caso: en labs avanzados puede que configures tu propio dominio para apuntar a la IP de una instancia (ej: un sitio web personalizado). Entonces usarás un servicio DNS (quizá Route 53 de AWS) para crear un registro tipo A que mapee www.midominio.com a la IP pública X de tu instancia. Así tus usuarios usan el nombre, no la IP directamente.

En resumen, DNS es esencial para la usabilidad. A efectos prácticos, cuando todo funciona no notas su presencia; pero cuando falla, de pronto “no hay internet” (porque ningún nombre resuelve). En la nube, la mayoría de veces se configura automáticamente, pero conviene saberlo: si tu instancia no se puede conectar a updates.ubuntu.com pero sí al 91.189.88.152 (IP de ubuntu updates), es síntoma de problema DNS. Y si montas redes privadas sin Internet, necesitarás igualmente resolver nombres privados o públicos (vía DNS interno o vinculado a DNS on-premise).

Recapitulando: DNS traduce nombres ↔ IPs, como un servicio de agenda ￼. Es invisible pero crítico en cloud y fuera de cloud. AWS tiene su propio Amazon DNS interno para VPC, y también ofrece Route 53 para gestionar nombres de dominios propios. No necesitas memorizar IPs de instancias si puedes usar sus nombres, o mejor aún, si configuras un DNS interno para tu aplicación (aunque en labs pequeños con pocas instancias usar IPs directas no es fin del mundo, pero no escalable).

### Acceso remoto (SSH y requisitos para conectar)

Al lanzar instancias en AWS (sobre todo Linux), una de las primeras cosas que querrás es conectarte remotamente a ellas para administrarlas. Aquí entra SSH (Secure Shell), el protocolo por excelencia para acceso remoto seguro a máquinas Linux/Unix. ¿Qué es SSH? Es un protocolo que te permite abrir una consola/terminal en otra máquina de forma segura (cifrada) a través de la red. Funciona con un modelo cliente-servidor: tu PC actúa como cliente SSH y la instancia AWS corre un servidor SSH (por defecto, la mayoría de AMIs Linux ya tienen sshd funcionando). Cuando te conectas, estableces una sesión cifrada donde puedes ejecutar comandos como si estuvieras frente a la máquina.

Con SSH puedes hacer prácticamente todo en una instancia en modo texto (instalar paquetes, editar config, ver logs…). Es la ventana de administración principal. Alternativas en Windows son RDP (escritorio gráfico remoto), pero para Linux SSH manda.

¿Qué necesita un alumno (o cualquiera) para poder conectarse a una instancia por SSH? Hay varios requisitos imprescindibles:
	1.	Dirección accesible de la instancia: en AWS, si estás desde internet, eso significa que la instancia tenga una IP pública o un nombre DNS público asociado a una IP pública. Si la instancia solo tiene IP privada, solo podrás SSH si estás conectado a la misma red interna (por ejemplo, conectado por VPN a la VPC, o desde un bastion host público dentro de la VPC). En labs iniciales normalmente se asigna IP pública a las instancias para que los alumnos accedan fácilmente.
	2.	Puerto 22 abierto en el firewall (Security Group): el servidor SSH por defecto escucha en el puerto 22. El SG de la instancia debe tener una regla inbound permitiendo el puerto 22 desde la IP o rango del alumno. Por ejemplo, permitir SSH desde “MiIP/32” o quizás desde 0.0.0.0/0 (aunque esto último es menos seguro porque permitiría intentos de cualquiera). Si este puerto está bloqueado, la conexión será rechazada o agotará tiempo.
	3.	Credenciales de acceso (clave privada SSH): AWS no usa usuario/contraseña tradicionales para instancias Linux (a menos que las configures). En su lugar, utiliza pares de claves SSH. Cuando lanzas una instancia, especificas o generas una key pair (par de claves) y descargas la clave privada (.pem). La instancia almacena la clave pública correspondiente. Para iniciar sesión, debes presentar tu clave privada al cliente SSH y este hace autenticación sin contraseña (clave pública/privada). ¡Es crucial guardar bien la clave .pem! Sin ella, no podrás autenticarte (a menos que configures otro método después). En términos prácticos: el alumno debe tener el archivo .pem correcto y usar un comando del tipo ssh -i miclave.pem usuario@IP (o su equivalente en PuTTY si está en Windows y convirtió la clave a .ppk). El usuario también importa: para Amazon Linux es ec2-user, para Ubuntu es ubuntu, para RHEL ec2-user o root dependiendo, etc. AWS suele indicar el nombre de usuario según la AMI.
	4.	Software cliente SSH en su equipo: Hoy día todos los OS vienen con uno (Windows 10+ ya trae OpenSSH en terminal, Mac/Linux traen terminal SSH). O pueden usar PuTTY/Termius etc. Esto no es tanto un requisito de red, pero sí práctico: necesitar una herramienta para usar la clave y abrir la sesión.
	5.	Conectividad de red end-to-end: es decir, que nada en el camino lo impida. Por ejemplo, que tu red local no bloquee salidas por puerto 22 (algunas WiFi empresariales podrían bloquear SSH). O que la ruta esté bien (una mala ruta o NACL en AWS también podría impedirlo, aunque con SG bien y IGW debería estar ok). Pero normalmente si tienes IP pública y SG ok, la conectividad está. Puedes verificar con un ping (si ICMP está habilitado) o simplemente probando el ssh.

Ejemplo práctico: Tienes una instancia i-12345 en AWS. Le asignaste key pair alumno1.pem. Tiene IP pública 18.204.x.y. Configuras su Security Group para permitir SSH desde tu dirección (supongamos 80.35.50.60/32). En tu PC (80.35.50.60) abres terminal y escribes ssh -i alumno1.pem ec2-user@18.204.x.y. Si todo va bien, la primera vez te preguntará aceptar huella (dile yes) y luego estarás dentro con [ec2-user@ip-... ~]$. ¡Ya tienes control de la instancia! Si algo falla:
	•	Timeout o “No route to host”: probablemente IP o ruta mal (¿la instancia está encendida? ¿tiene IP pública? ¿subred tiene IGW?).
	•	“Permission denied” rápido: probablemente el SG no permitía SSH.
	•	“Permission denied (publickey)”: conectaste pero la clave no es aceptada -> usaste usuario o clave incorrectos.
	•	“Host not found”: error DNS -> tu cliente no pudo resolver el nombre (si usaste nombre en vez de IP, revisar DNS o usar IP).
	•	Conexión cerrada de inmediato: a veces firewall local de instancia rechaza, o falta algo en config.

SSH en contexto Cloud: En labs AWS normalmente todos los alumnos descargan una clave privada para sus instancias. Es fundamental mantener esa clave privada segura (no compartirla) y dar los permisos adecuados al archivo (chmod 400 en Linux) para que SSH la use. También, si trabajas desde la facultad, quizás la IP de la sala es compartida y el SG de AWS tiene que permitirla. O se puede permitir rango amplio provisionalmente. La idea es concientizar que sin la trifecta IP pública + puerto 22 abierto + clave correcta, no habrá acceso. Tip: Si por error lanzas instancia sin IP pública, aún podrías acceder si lanzas otra instancia en la misma VPC que sí tenga (bastion) y desde allí entrar a la privada vía IP privada + clave (pero eso es más avanzado).

Por último, mencionar RDP para Windows: Si tu instancia es Windows, usarás RDP en vez de SSH. RDP usa puerto 3389 TCP, y en AWS la autenticación es con usuario (Administrator) y una contraseña que se obtiene desencriptando con la key pair. Pero en ambos casos necesitas IP pública o VPN, SG abierto en 3389, etc.

### VPN (concepto y ejemplo práctico)

VPN = Virtual Private Network o red privada virtual. Es una tecnología que permite establecer una conexión segura (encriptada) sobre Internet de tal forma que un dispositivo remoto se integra a una red local como si estuviera físicamente allí. Dicho de otro modo, una VPN crea un “túnel” cifrado a través de la red pública que conecta dos extremos privados ￼ ￼. Así, equipos de un lado pueden comunicarse con recursos del otro lado de forma segura y transparente, porque el túnel hace que todo el tráfico parezca local.

¿Para qué sirve una VPN? Tiene muchos usos:
	•	Acceso remoto seguro de usuarios individuales: Por ejemplo, un alumno desde casa puede activar una VPN que lo conecte a la red interna del instituto. Una vez conectada, su PC obtiene quizás una IP interna del campus y puede acceder a recursos restringidos (como si estuviera dentro de la escuela), a través de Internet pero cifrado. Esto se llama VPN de acceso remoto.
	•	Interconexión de redes (sitio a sitio): Por ejemplo, una empresa conecta su oficina central con su VPC en AWS mediante VPN. En cada extremo hay un gateway VPN (un router o firewall con capacidad VPN), negocian un túnel cifrado entre ellos, y ¡voilà! la red de la oficina y la red de la VPC se ven mutuamente. Esto se llama VPN site-to-site. Desde la perspectiva de un servidor en AWS, los PCs de la oficina podrían llegarle por su IP privada a través del túnel, como si todos formaran parte de la misma LAN extendida (por eso “Red Privada Virtual”).
	•	Privacidad/Anonimato en Internet: Mucha gente usa VPN personales (tipo NordVPN, ExpressVPN) que cifran su tráfico y salen a Internet por otro país, etc., para proteger datos en WiFi públicas o sortear restricciones. No es foco de este curso, pero es otra aplicación (en ese caso la VPN conecta tu dispositivo con un servidor VPN en otro lugar, y tu navegación sale por ese servidor).

Focalicemos en entornos cloud: Conectar oficina con cloud. Si una empresa ya tiene su LAN local y empieza a usar AWS, puede montar una VPN AWS (AWS Site-to-Site VPN) entre su router on-premise y un Virtual Private Gateway en la VPC ￼. Así, los servidores en AWS (en subred “only VPN”) podrán comunicarse con la red local de forma segura ￼. Esto es útil para, digamos, extender tu datacenter al cloud: tus apps en AWS podrían consultar la base de datos que está en tu oficina mediante VPN, o viceversa. AWS también ofrece Client VPN para que usuarios remotos se conecten a la VPC, similar a conectarse a la oficina. En labs académicos, podrías usar una VPN si tu instancia no tiene IP pública: conectas tu PC a la VPC via VPN y ya tienes acceso a las IP privadas. Sin embargo, configurar una VPN requiere pasos adicionales y quizás no lo hagan en los primeros labs.

¿Cómo funciona la VPN? A alto nivel, dos extremos crean un túnel cifrado. Todo paquete que sale de un lado se cifra y se encapsula para viajar por Internet hasta el otro lado, donde se decapsula. Piensa en el túnel como un sobre cerrado: los datos viajan seguros dentro de él. Protocolos comunes de VPN incluyen IPsec (nivel red) y TLS/SSL (nivel aplicación, como OpenVPN). Una vez establecido, los dispositivos se comportan como si estuvieran en la misma red privada. Por eso decimos “virtual” (no es un cable físico, es sobre Internet), pero “privada” (porque nadie más puede leerla, va cifrado).

Ejemplo concreto: Imagina que montas una máquina VPN en AWS y la configuras tipo OpenVPN. Te conectas desde tu portátil de casa con las credenciales, y de pronto tu portátil tiene IP 10.0.8.10 que es parte de la VPC de AWS. Ahora puedes hacer SSH a la instancia privada 10.0.1.5 como si estuvieras en la red de AWS, aunque físicamente estés en casa. Todo el tráfico entre tu portátil y AWS va cifrado por Internet, así que es seguro incluso si lo haces desde una WiFi de cafetería. Otro ejemplo, más empresarial: tu empresa ACME tiene la red 192.168.10.0/24 en la oficina y la VPC 10.0.0.0/16 en AWS. Configuran un VPN IPsec entre el firewall SonicWall de la oficina y el gateway de AWS. Tras eso, los PCs 192.168.10.x pueden acceder a servidores 10.0.x.y de AWS y viceversa, sin pasar por internet abierta. Para los usuarios, el servidor en AWS podría incluso resolverse con un nombre interno y parecer un servidor más de su LAN.

¿Por qué “nivelación” en este tema? Porque en cloud es común que para entornos híbridos necesites VPN o conexiones privadas (Direct Connect). No entraremos a configurarlos aquí, pero debes saber qué es: tunel seguro que une redes separadas. Así, si lees “esta instancia solo es accesible vía VPN” entiendes que no tiene IP pública; debes estar conectado mediante la red privada virtual para llegar a ella. O si se dice “conectaremos la VPC a on-prem mediante VPN site-to-site”, sabes que habrá un tunel cifrado constante. Y al solucionar un problema: si la VPN cae, de pronto los recursos no se ven. Diagnóstico allí es otro cantar (ver logs de túnel, etc.), pero conceptualmente, VPN = acceso seguro a red remota.

Diagnóstico básico de red (ping, traceroute y fallos típicos)

Por último, veamos algunas herramientas básicas de diagnóstico de red que te ayudarán a identificar problemas de conectividad: ping y traceroute (en Windows se llama tracert). Seguramente ya las has usado, pero las pondremos en contexto cloud.

Ping: Es la forma más simple de comprobar si un host está activo y accesible en la red. El comando ping envía paquetes especiales ICMP Echo Request (ping) al destino, y espera ICMP Echo Response (pong). Si recibe respuesta, significa que:
	•	El paquete llegó al destino y volvió, por tanto hay conectividad IP entre tú y el destino.
	•	Además, te da el tiempo de ida y vuelta (latencia), útil para ver si la conexión es rápida o hay retraso (p. ej. ping de 20ms vs 200ms vs 2000ms).
	•	Si no hay respuesta, puede indicar que el host está caído, o no hay ruta, o simplemente que el firewall bloquea ICMP (muchos sitios lo bloquean).

En una instancia AWS, por defecto el Security Group bloquea ICMP (a menos que agregues regla de “All ICMP” o Echo). Así que si intentas ping a la IP pública de tu instancia recién creada, es probable que obtengas timeout. Esto no necesariamente significa que la instancia esté apagada; puede ser el firewall. Por ende, ping es útil pero con precaución: “no hace ping” no siempre = “no está funcionando”. Sin embargo, dentro de una VPC, puedes habilitar ping entre instancias (abriendo ICMP) para comprobar que se ven. O hacer ping a un recurso externo (8.8.8.8) para verificar que tu instancia tiene salida a Internet.

Traceroute: Es la herramienta para trazar la ruta que siguen los paquetes hacia un destino, pasando por todos los routers intermedios. Básicamente hace múltiples pings con incrementos en el TTL (tiempo de vida) para provocar que cada router en la ruta responda, listándolos uno a uno ￼ ￼. El resultado es una lista de saltos: te muestra por qué nodos pasa la conexión. Por ejemplo, un traceroute de tu PC a una instancia AWS puede mostrar hops saliendo de tu ISP, pasando por redes troncales, llegando a la red de Amazon y finalmente a la instancia (o más bien al último router antes de ella). ¿Para qué sirve? Principalmente para diagnosticar dónde se produce un problema o retardo. Si te quedas en el salto 5 y luego timeout, sabes que a partir de cierto punto no hay respuesta (posible firewall, o red caída). Traceroute también revela si la ruta es indirecta. En entornos AWS, puedes usar traceroute desde una instancia para ver cómo sale a Internet, o desde tu PC a ver cómo entra. Ten en cuenta que algunos routers (especialmente en la red de AWS) podrían no responder a traceroute (aparecen como * * * asteriscos) porque bloquean ICMP o de propósito no revelan su presencia ￼. Aun así, obtienes la mayoría de saltos.

Ejemplo de diagnóstico: Supongamos que “no me conecto a mi instancia”. ¿Cómo abordar?:
	1.	Ping a la IP:
	•	Si responde, al menos la instancia está activa y accesible a nivel IP/ICMP. Si no, puede estar apagada, sin internet, o firewall ICMP bloqueado. Un ping fallido no es conclusivo pero da pistas.
	2.	Telnet o nc al puerto 22 (o usando ssh -v para ver detalles):
	•	¿Se puede abrir conexión TCP al 22? Si no, es probable un firewall SG bloquea o no hay ruta (o servicio ssh caído). Si sí se abre pero luego se cierra, podría ser credenciales.
	3.	Traceroute:
	•	Si muere cerca del destino, podría ser que la instancia no tiene ruta de vuelta (e.g. falta IGW o NAT), o NACL bloquea. Si muere en mitad de internet, un problema de proveedor.
	•	Por ejemplo, traceroute desde tu PC a la IP pública de la instancia: si ves que llega hasta la red de Amazon y luego timeout en el último salto, sospecha de SG o host firewall bloqueando.
	•	Traceroute desde la instancia hacia tu IP (o 8.8.8.8) también útil: si no sale de la VPC, quizás no hay IGW o NAT (salto 1 es router VPC, luego nada).
	4.	Revisar configuración AWS: ¿Instancia en subred pública con IGW? ¿Tiene IP pública asociada? ¿SG permite 22 desde tu IP? Estas suelen ser las causas #1 de “no me conecto”.
	5.	Caso práctico: Si un alumno dice “no puedo hacer SSH a la instancia”, revisar: – ¿Se abrió puerto 22 en SG? – ¿Estás usando la IP pública correcta? – ¿Tu máquina está en internet? – ¿La instancia está en running? – ¿Clave correctay chmod 400? – Si todo parece correcto, probar ping/traceroute: ping no responde (posible ICMP block, ok), traceroute muestra ruta bien hasta AWS, ergo conectividad hay hasta allá, entonces probablemente es SG. O tal vez olvidó asociar la IP elástica o la instancia no tiene IP pública!

Ping en AWS Labs: A veces en labs se permite ping entre instancias para probar conexión privada: debes permitir ICMP Echo en los SG de ambas. ping puede decirte “sí hay red L3 entre A y B”. Si no hay ping, quizá están en subredes distintas sin ruta, o en diferentes VPC (incomunicadas), etc.

Otro uso – medir latencia: Ping te dice el delay. Entre tu PC y AWS podrás ver quizás 50ms (depende distancia), entre instancias en misma AZ <1ms, en distinta AZ unos ms, etc. Interesante para saber penalizaciones de red.

En síntesis, ping = comprobar alcance y tiempo, traceroute = mapear el camino ￼ ￼. Son tus amigos cuando algo no responde. Siempre ten en cuenta firewalls que puedan interferir en sus resultados. Al terminar esta unidad, deberías poder pensar: “No puedo acceder a X, ¿hago ping? ¿traceroute? A ver dónde se corta…”, y combinar con revisar SG/NAT/etc., para deducir la causa.



### Conclusión y próximos pasos

Hemos cubierto los 11 temas clave de redes que te preparan para trabajar con cloud:
	•	Qué es una red (LAN/WAN/Internet) y estar “conectado”.
	•	Direcciones IP (identidad en la red), públicas vs privadas.
	•	Subredes y máscaras (segmentar redes, especialmente en AWS VPC).
	•	NAT e Internet en AWS (salida para instancias privadas, IGW para públicas).
	•	DHCP (asignación automática de IPs, cambios de direcciones).
	•	Puertos y protocolos (puerta lógica de servicios; 22, 80, 443; TCP vs UDP).
	•	Firewall (filtros de puertos; SG de AWS vs firewall del SO).
	•	DNS (resolución de nombres, agenda de Internet).
	•	Acceso remoto (SSH; necesitar IP, puerto 22 abierto, clave).
	•	VPN (túnel seguro para conectar redes o clientes remotos).
	•	Diagnóstico básico (ping/traceroute para verificar conexión).

Con este conocimiento, cuando en los laboratorios AWS veas términos como “configure la VPC y subnets”, “asocie un Elastic IP”, “abra el puerto 80 en el SG”, “la instancia no tiene salida a internet”, “conéctese por SSH utilizando la clave”, “establezca una VPN Site-to-Site para la conexión on-premises”, etc., tendrás una base sólida para entender de qué se habla y por qué.

Glosario Rápido:
	•	Red LAN/WAN: LAN es red local (pequeña, alta velocidad) ￼, WAN es red de amplia área (larga distancia, une LANs) ￼. Internet es la WAN global ￼.
	•	Dirección IP: Identificador único numérico de un dispositivo en la red (ej. 192.168.1.50) ￼. Necesario para enviar datos al destinatario correcto.
	•	IP Pública/Privada: Pública es global, única en Internet; privada solo válida en redes internas ￼. Rangos privados comunes: 10.x.x.x, 172.16-31.x.x, 192.168.x.x ￼.
	•	Subred: Porción de una red dividida lógicamente. Tiene un rango de IP más pequeño dentro de uno mayor ￼. En AWS, subred pública (con IGW) vs privada (sin IGW) ￼.
	•	Máscara de subred: Notación (ej. /24) que indica qué parte de la IP es la red. Define el tamaño de la subred.
	•	NAT (Network Address Translation): Traducción de IP privadas a una pública para permitir salida a Internet compartida ￼. Impide accesos entrantes no solicitados.
	•	Internet Gateway (IGW): Puerta de enlace de una VPC a Internet. Necesaria para que IPs públicas funcionen ￼.
	•	DHCP: Protocolo que asigna IP automáticamente a dispositivos al conectarse ￼ (junto a gateway, DNS…). Hace que las IP puedan cambiar dinámicamente.
	•	Puerto: Número que identifica un servicio en un host (0-65535). Ej: puerto 22=SSH, 80=HTTP, 443=HTTPS ￼ ￼.
	•	Protocolo TCP/UDP: TCP fiable orientado a conexión (uso general web, SSH) ￼; UDP no orientado y sin garantias pero rápido (stream, DNS) ￼.
	•	Firewall: Filtro de tráfico por reglas. Puede bloquear puertos, IPs, etc. SG de AWS es un firewall virtual por instancia ￼.
	•	Security Group: Firewall de AWS asociado a instancia; define tráfico permitido entrante/saliente ￼.
	•	DNS: Sistema de Nombres de Dominio. Traduce nombres legibles (ej. ejemplo.com) a IPs y viceversa ￼. Como una agenda telefónica de Internet.
	•	SSH: Secure Shell, protocolo de acceso remoto seguro a una consola de otro host (Linux). Usa claves y puerto 22.
	•	Clave (Key Pair) AWS: Par criptográfico para SSH. La privada (.pem) la tiene el usuario, la pública se instala en la instancia para autenticar sin password.
	•	VPN: Red privada virtual. Túnel cifrado sobre Internet que conecta redes o usuarios de forma segura ￼. Ej: VPN sitio-a-sitio oficina↔AWS ￼, o VPN de cliente para teletrabajo.
	•	Ping: Comando para probar conectividad con ICMP Echo. Respuesta indica host alcanzable y da tiempo (latencia).
	•	Traceroute: Comando para listar la ruta (hops) que siguen los paquetes hasta destino ￼. Útil para localizar dónde se corta o ralentiza la conexión.
	•	Salida a Internet: Capacidad de una instancia/red de iniciar conexiones hacia Internet. Requiere ruta IGW/NAT y a veces IP pública. “Sin salida a internet” = aislado, no puede navegar/actualizar.
	•	Entrada desde Internet: Capacidad de recibir conexiones iniciadas desde fuera (requiere IP pública + puertos abiertos + ruta IGW).

Con todo esto, estás listo para enfrentar los labs de Cloud AWS Fundamentals sin miedo a la palabra “red”. 🤓¡Manos a la obra! Y recuerda: si algo no conecta, revisa IP → Puertos → Firewall → Rutas/DNS; la solución suele estar allí. ¡Éxitos en la nube! ￼ ￼