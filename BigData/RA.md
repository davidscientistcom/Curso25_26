
### **Módulo Profesional: Sistemas de Big Data (Código: 5074)**

#### **Resultados de Aprendizaje y Criterios de Evaluación**

1.  **Aplica técnicas de análisis de datos que integran, procesan y analizan la información, adaptando e implementando sistemas que las utilicen**.
    * Se han identificado conceptos básicos de matemática discreta, lógica algorítmica y complejidad computacional, y su aplicación para el tratamiento automático de la información por medio de sistemas computacionales.
    * Se ha extraído de forma automática información y conocimiento a partir de grandes volúmenes de datos.
    * Se han combinado diferentes fuentes y tipos de datos.
    * Se ha construido un conjunto de datos complejos y se han relacionado entre sí.
    * Se han establecido objetivos y prioridades, secuenciación y organización del tiempo de realización.
    * Se han seleccionado e integrado sistemas de información que satisfacen las necesidades del problema[cite: 596, 597].
    * Se han determinado criterios de coste y calidad necesarios para la eficacia y eficiencia de la implementación de un sistema Big Data.

2.  **Configura cuadros de mando en diferentes entornos computacionales usando técnicas de análisis de datos**.
    * Se han clasificado diferentes librerías e implementaciones de las técnicas de representación de la información.
    * Se ha cruzado información sobre el objetivo a conseguir y la naturaleza de los datos.
    * Se ha realizado un cuadro de mandos utilizando técnicas sencillas.
    * Se han utilizado técnicas predictivas complejas para anticiparse a lo que ocurra.
    * Se ha evaluado el impacto del análisis de datos en la consecución de los objetivos propuestos.

3.  **Gestiona y almacena datos facilitando la búsqueda de respuestas en grandes conjuntos de datos**.
    * Se han extraído y almacenado datos de diversas fuentes, para ser tratados en distintos escenarios.
    * Se ha fijado el objetivo de extraer valor de los datos para lo que es necesario contar con tecnologías eficientes.
    * Se ha comprobado que la revolución digital exige poder almacenar y procesar ingentes cantidades de datos de distinto tipo y descubrir su valor.
    * Se han desarrollado sistemas de gestión, almacenamiento y procesamiento de grandes volúmenes de datos de manera eficiente y segura, teniendo en cuenta la normativa existente.
    * Se han utilizado habilidades científicas en entornos de trabajo multidisciplinares.

4.  **Aplica herramientas para la visualización de datos utilizadas en las soluciones Big Data facilitando las tareas de análisis y presentación de resultados**.
    * Se han examinado distintos escenarios y tipologías de datos no estructurados.
    * Se ha implantado la aplicación de la BI (Business Intelligence) para la extracción de valor.
    * Se ha reconocido la importancia de almacenar grandes volúmenes de datos de forma distribuida y redundante en un clúster de máquinas.
    * Se han determinado las diferencias en el entorno de aplicaciones relacionadas que facilitan el procesamiento de datos de manera rápida, eficiente y eficaz.
    * Se ha comprobado la manera de programar y procesar automáticamente la estructura de datos.
    * Se han valorado las diferentes formas de visualizar los datos que nos interese representar gráficamente, facilitando así las tareas de análisis y presentación de resultados[cite: 620, 621, 629].

#### **Contenidos Básicos** 

* **Aplicación de técnicas de integración, procesamiento y análisis de información**:
    * Conceptos básicos de matemática discreta, lógica algorítmica y complejidad computacional para análisis de datos.
    * Técnicas y procesos de extracción de la información de los datos.
    * Modelado, razonamiento, resolución de problemas.
    * Análisis en tiempo real.
    * Costes y calidad asociados al proceso de análisis de la información.
* **Configuración de cuadros de mando en entornos computacionales**:
    * Técnicas de representación de información. Librerías e implementaciones. Estructuración de datos. Objetivos a cumplir.
    * Cuadro de mando: Fundamentos.
    * Métricas.
    * Principales métodos y algoritmos en la minería de datos. Modelos SEMMA y CRISP-DM.
    * Fases de los modelos. Valoración. Interpretación. Despliegue.
* **Gestión y almacenamiento de datos. Búsqueda de respuestas en grandes conjuntos de datos**:
    * Sistemas de gestión. Almacenamiento.
    * Importación: Flume, Sqoop.
    * Integración de datos.
    * Programación: R y Python.
* **Aplicación de herramientas para la visualización de datos**:
    * Datos no estructurados: Fuentes, tipología.
    * Inteligencia artificial en el análisis de datos.
    * Clúster de máquinas: Información distribuida y redundante.
    * Herramientas de visualización de datos: QlikView, Qlik Sense, Tableau, Power BI, entre otras.
    * Tendencias de visualización de datos.

---

### **Módulo Profesional: Big Data Aplicado (Código: 5075)**

#### **Resultados de Aprendizaje y Criterios de Evaluación**

1.  **Gestiona soluciones a problemas propuestos, utilizando sistemas de almacenamiento y herramientas asociadas al centro de datos**.
    * Se ha caracterizado el proceso de diseño y construcción de soluciones en sistemas de almacenamiento de datos.
    * Se han determinado los procedimientos y mecanismos para la ingestión de datos.
    * Se ha determinado el formato de datos adecuado para el almacenamiento.
    * Se han procesado los datos almacenados.
    * Se han presentado los resultados y las soluciones al cliente final en una forma fácil de interpretar[cite: 684, 685].

2.  **Gestiona sistemas de almacenamiento y el amplio ecosistema alrededor de ellos facilitando el procesamiento de grandes cantidades de datos sin fallos y de forma rápida**.
    * Se ha determinado la importancia de los sistemas de almacenamiento para depositar y procesar grandes cantidades de cualquier tipo de datos rápidamente.
    * Se ha comprobado el poder de procesamiento de su modelo de computación distribuida.
    * Se ha probado la tolerancia a fallos de los sistemas.
    * Se ha determinado que se pueden almacenar tantos datos como se desee y decidir cómo utilizarlos más tarde[cite: 697, 698].
    * Se ha visualizado que el sistema puede crecer fácilmente añadiendo módulos.

3.  **Genera mecanismos de integridad de los datos, comprobando su mantenimiento en los sistemas de ficheros distribuidos y valorando la sobrecarga que conlleva en el tratamiento de los datos**.
    * Se ha valorado la importancia de la calidad de los datos en los sistemas de ficheros distribuidos.
    * Se ha valorado que a mayor volumen de tratamiento de datos corresponde un mayor peligro relacionado con la integridad de los datos.
    * Se ha reconocido que los sistemas de ficheros distribuidos implementan una suma de verificación para la comprobación de los contenidos de los archivos.
    * Se ha reconocido el papel del servidor en los procesos previos a la suma de verificación.

4.  **Realiza el seguimiento de la monitorización de un sistema, asegurando la fiabilidad y estabilidad de los servicios que se proveen**.
    * Se han aplicado herramientas de monitorización eficiente de los recursos.
    * Se han recogido métricas, procesamiento y visualización de los datos.
    * Se han generado alertas para detectar un riesgo o mal funcionamiento.
    * Se ha comprobado que las herramientas usadas ofrecen un rendimiento elevado con rapidez.
    * Se ha comprobado la fiabilidad de los datos según respuestas.
    * Se ha analizado la estabilidad de servicios[cite: 713, 714].

5.  **Valida las técnicas de Big Data para transformar una gran cantidad de datos en información significativa, facilitando la toma de decisiones de negocios**.b
    * Se han seleccionado gran cantidad de datos estructurados y no estructurados para reforzar la función de BI.
    * Se ha realizado la limpieza y transformación de datos en base a los objetivos predeterminados.
    * Se ha comprobado que el Big Data multiplica la relevancia y la utilidad del BI para el negocio.
    * Se han conjugado dentro de un modelo de empresa datos de clientes, financieros, de ventas, de productos, de marketing, de redes sociales, de la competencia, entre otros, para extraer un análisis valioso y efectivo para el negocio.
    * Se ha evaluado e interpretado la información extraída de los datos y su influencia en el triunfo de diferentes negocios.
    * Se ha simulado la implantación de un modelo de Inteligencia de negocios BI.

#### **Contenidos Básicos** 

* **Gestión de soluciones con sistemas de almacenamiento y herramientas del centro de datos para la resolución de problemas**:
    * Almacenamiento de datos masivo.
    * Procesamiento de datos.
    * Analítica de Big Data en los ecosistemas de almacenamiento.
    * Big Data y Cloud.
* **Gestión de sistemas de almacenamiento y ecosistemas Big Data**:
    * Computación distribuida. Computación paralela.
    * Sistemas de almacenamiento distribuidos. Tolerancia a fallos.
    * Herramientas: MapReduce, Pig, Hive, Flume, Sqoop, Oozie, entre otras[cite: 739, 740, 741, 742, 745].
    * Automatización de Jobs.
    * Consultas Pig y Hive.
* **Generación de mecanismos de Integridad de los datos. Comprobación de mantenimiento de sistemas de ficheros**:
    * Calidad de los datos.
    * Comprobación de la integridad de datos de los sistemas de ficheros distribuidos. Sumas de verificación.
    * Movimiento de datos entre clústeres. Actualización y migración. Metadatos.
* **Monitorización, optimización y solución de problemas**:
    * Herramientas de monitorización: Interfaz web del Jobtracker y Namenode, entre otras.
    * Análisis de los históricos.
    * Monitorización del clúster: Ganglia, entre otros.
* **Validación de técnicas Big Data en la toma de decisiones en Inteligencia de negocios BI**:
    * Modelos de Inteligencia de negocios.
    * Proceso del modelo KDD (Knowledge Discovery in Databases). Etapas: Selección, limpieza, transformación de datos, minería de datos, interpretación y evaluación de datos.
    * Implantación de modelos de inteligencia de negocios BI.
    * Técnicas de validación de modelos BI.



Comprendo perfectamente tu duda. La superposición de contenidos es una característica inherente al diseño curricular por competencias, donde los conceptos se reintroducen en diferentes contextos para reforzar el aprendizaje. Sin embargo, cada módulo tiene un **núcleo teleológico distinto**. Analicémoslo con el rigor que merece.

Dado tu perfil, pensemos en esto como la diferencia entre aprender los fundamentos de las capas de una red neuronal y, posteriormente, diseñar y entrenar una arquitectura completa para resolver un problema específico de visión por computador.

---

### ## Frontera Conceptual y Objetivos de los Módulos de Big Data

La clave para diferenciar los módulos **5074 - Sistemas de Big Data** y **5075 - Big Data Aplicado** no reside tanto en los *contenidos temáticos* aislados (que necesariamente se solapan), sino en su **finalidad pedagógica y el nivel de abstracción**.

#### **Módulo 5074: Sistemas de Big Data (El Módulo Fundacional y de Herramientas)** ⚙️

Este módulo es el pilar teórico y práctico sobre el que se construye todo lo demás. Su objetivo principal es que el alumnado adquiera un dominio conceptual y técnico de las **herramientas y técnicas individuales** que componen el ecosistema Big Data.

* **Enfoque:** Se centra en el **"qué"** y el **"cómo"** de cada componente. ¿Qué es un sistema de ficheros distribuido? ¿Cómo se configura un cuadro de mandos? ¿Qué técnicas de visualización existen? ¿Cuáles son los fundamentos matemáticos y algorítmicos?[cite: 584, 599, 606, 613].
* **Abstracción:** Opera a un nivel más bajo, enfocado en la **capacidad de la herramienta**. El estudiante aprende a usar el "martillo" (ej. Hadoop), el "destornillador" (ej. Python con librerías de análisis) y la "sierra" (ej. Tableau/Power BI)[cite: 647, 651].
* **Resultado de Aprendizaje Clave:** Al finalizar, el alumno debe ser capaz de **aplicar técnicas y herramientas específicas** para integrar, procesar, analizar y visualizar datos[cite: 584, 613]. Es un módulo de adquisición de *capacidades*.

En esencia, **Sistemas de Big Data** te proporciona la caja de herramientas y te enseña a manejar cada una de ellas con solvencia.

#### **Módulo 5075: Big Data Aplicado (El Módulo de Integración y Soluciones de Negocio)** 📈

Este módulo eleva el nivel de abstracción. Ya no se trata de manejar herramientas aisladas, sino de **diseñar, implementar y gestionar soluciones de negocio de extremo a extremo (end-to-end)** que resuelvan problemas reales.

* **Enfoque:** Se centra en el **"por qué"** y el **"para qué"**. ¿Por qué elegimos esta arquitectura y no otra? ¿Cómo gestionamos todo el *pipeline* de datos, desde la ingesta hasta la entrega de valor al cliente?[cite: 679, 686].
* **Abstracción:** Opera a un nivel de sistema y de proyecto. El estudiante no solo usa las herramientas, sino que las **orquesta dentro de un ecosistema** para construir una solución coherente, monitorizada y robusta[cite: 686, 706].
* **Resultado de Aprendizaje Clave:** Al finalizar, el alumno debe ser capaz de **gestionar soluciones completas**, validar técnicas en el contexto de la inteligencia de negocio (BI) y asegurar la integridad y monitorización del sistema completo[cite: 679, 706, 715]. Es un módulo de *aplicación e integración*.

En definitiva, **Big Data Aplicado** te da un plano y un problema de negocio (ej. "optimizar la logística"), y tú debes usar la caja de herramientas del módulo anterior para construir la solución completa, asegurando que funcione de manera fiable y aporte valor.

| Característica | **5074 - Sistemas de Big Data** | **5075 - Big Data Aplicado** |
| :--- | :--- | :--- |
| **Analogía** | Aprender a usar cada herramienta del taller. | Construir un producto complejo usando todas las herramientas. |
| **Foco** | Capacidades técnicas individuales. | Soluciones de negocio integradas. |
| **Pregunta Guía** | ¿Cómo funciona y se usa esta tecnología? | ¿Cómo resolvemos este problema de negocio con un pipeline de datos? |
| **Resultado** | Dominio de herramientas y técnicas. | Capacidad de gestión de proyectos y ecosistemas. |

---

### ## Viabilidad de Impartir otros Módulos (Análisis de Datos y Machine Learning)

Respecto a tu segunda pregunta, la capacidad para "salvar los muebles" no depende de tu solvencia técnica (que, dado tu doctorado, es indudable), sino de lo que estipula el **Real Decreto** en cuanto a la atribución docente. Aquí la normativa es taxativa.

Observando el **ANEXO III A) del Real Decreto**, se establece una división clara:

1.  **Módulos de Big Data (los que te competen):**
    * `5074. Sistemas de Big Data`
    * `5075. Big Data aplicado`
    * **Cuerpo:** Profesores Técnicos de Formación Profesional.
    * **Especialidades:** Equipos Electrónicos, Instalaciones Electrotécnicas, Sistemas y Aplicaciones Informáticas.

2.  **Módulos de IA y Machine Learning:**
    * `5072. Sistemas de aprendizaje automático` (Machine Learning)
    * `5071. Modelos de Inteligencia Artificial` (que incluye la base del análisis de datos)
    * **Cuerpo:** Catedráticos de Enseñanza Secundaria / Profesores de Enseñanza Secundaria.
    * **Especialidades:** Informática, Sistemas Electrónicos, Sistemas Electrotécnicos y Automáticos.

**Conclusión Normativa:**

Estrictamente, según la atribución docente especificada en el Real Decreto, las especialidades y los cuerpos docentes requeridos para impartir los módulos de Machine Learning e IA son **diferentes** de los requeridos para los módulos de Big Data.

Por tanto, si tu plaza y especialidad se enmarcan dentro del cuerpo de "Profesores Técnicos de Formación Profesional" con las especialidades asociadas a Big Data, **no tendrías la atribución directa** para impartir los módulos de "Sistemas de aprendizaje automático" o "Modelos de Inteligencia Artificial".

La única figura que podría ofrecer flexibilidad es la del **"Profesor Especialista"**, que se contempla para todos los módulos. Esta es una vía que la administración educativa podría utilizar para contratar a un experto en la materia (como tú) de forma no permanente para impartir un módulo específico, basándose en la experiencia profesional y conocimientos acreditados. Sin embargo, esto depende de los procedimientos y la voluntad de la consejería de educación correspondiente.